一、不允许使用rand函数来解决shuffle倾斜问题。
作业在进行的shuffle的时候，同一行数据，shuffle的结果不是幂等的。
如果shuffle的mapper task由于失败重算，就有可能导致shuffle的数据分配错误。

推荐使用-1 - abs(hash(col1, col2, ...) % 99) ，生成结果是确定的。

注意:公式原因
从rand改成hash的时候，要注意int数据溢出的问题。
比如有些场景rand乘以一个负数，用 rand()*-99 获取 （-99，0] 之间的随机小数。
但是如果直接用abs(hash(col))乘以-99，结果可能溢出，结果不是负数。
这种情况下，可以改成abs(hash(col)  % 99) *-1，这样结果是(-99, 0] 之间的整数。
如果要不希望包括0 ，可以用-1 - abs(hash(col)  % 99) 

二、解决数据倾斜方案
1.将reduce join转为map join
2.提高shuffle操作的并行度（减少倾斜）---但针对null这种某一个值超级大,导致的倾斜，这个方案是无效的。
spark.sql.shuffle.partitions=4000
3.提前数据清理，过滤导致倾斜的key -- 针对null超级大的case,特别有效,但数据结果可能有问题。
4.两阶段聚合（先按key的某个hash聚合，再将结果全部聚合）
核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，
比如
(hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1)(2_hello, 1) (2_hello,1)。
接着对打上随机数后的数据，执行reduceByKey 等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello,2)。
然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。

仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。

5.热点key值加hash值（不能rand()、不支持幂等性Spark shuffle key中包含rand问题），比如null这类热点key。

from t1 left join t2 
on (t1.id = case when t2.id is not null then t2.id 
    else (-1 - abs(hash(t2.user_id)  % 99)) end )
    
实现原理:在加载t2表数据的时候，要按照key去分发数据。正常按照id去分发，这样保证t1和t2相同id的数据会在同一个节点上。
但如果id是null的时候，会导致该节点上null的数据非常多，又无法与t1匹配成功。


因此总之都无法与t1匹配成功，不如直接分发一个值，这样所有的null的数据应该分发到一台节点，就变成分发到多个节点了。此时并不影响结果，因为t1的id本身就不需要关联t2的null值。分发到哪个节点都无所谓。

那么有没有简单的方式呢？即这种情况下，如果直接把t2的null数据删除掉也是合理的，但很麻烦，因为你不确定t2是有null的，你需要做数据探查，这就会耗费时间了，所以不如直接用这种语法处理掉。

