场景
流量表中user和uuid大量无效的,会发生数据倾斜。
同时需要关联user和uuid的维度表，比如判断是否是大学生，判断uuid是否是新用户。

难点:
1.user和uuid维表也是非常大的表,存储历史全部用户信息，无法放到内存里。
2.而且uuid还不是int,而是字符串。


Hive的数据倾斜，一般都发生在Sql中Group和On上，而且和数据逻辑绑定比较深。

一、通过spark-sql页面，查看任务执行计划，是否合适。
1.是否有本地join的可能。select /*+MAPJOIN(city)*/
2.能否缩短查询数据量。减少字段的输出，只输出关键字段。
3.枚举的方式,判断是否有非null、非空的情况下,依然发生倾斜的数值。
比如流量表,设备id可能是null或者""，但最后发现依然有一些设备不符合规则的脏数据，这部分应该被处理掉。
或者流量表中，userid不仅有null和"",还有0和-1占比非常高，这就会出现数据倾斜(在0和1的值情况下倾斜，因为没有特殊处理)
4.解决数据倾斜，将数据不会关联成功的非法数据,打扫到多个节点去。
rand() 是0~1之间非常多小数位的小数。
on case when t1.user_id is null 
    or t1.user_id = '' 
    or t1.user_id = 'undefined' 
    or t1.user_id != '0' 
    or t1.user_id != '1' 
    or instr(t1.user_id,'2014070700000001') != 1 ###相当于indexof
    then concat('hive',rand() ) else t1.user_id end = ord.user_id
    
注意:
1.要判断主表是否有非命中case 中concat('hive',rand() )部分的倾斜数据，必须要覆盖全，否则还是会倾斜。
2.要校验从表不会有数据倾斜，避免从表某一些字段依然会数据倾斜的问题。

5.解决数据分布,避免小文件过多,以下sql只会产生500个小文件。
distribute by abs(hash(id) % 500)

6.如何排查是否数据倾斜。
a.查看耗时长的job。
b.进入耗时长的job,查看stage的Summary Metrics for统计值,max是否比75th percentile大很多。说明倾斜了。
查看task的duration指标，看看哪个子任务延迟最久。

二、解决方案:大表随机添加N种随机前缀，小表扩大N倍，属于大表加盐处理。
1.背景与方案:
比如A表有500万条数据,B表有100万条数据，则目标扩展10倍数据。
因此A表数据追加前缀(10随机数),由<ka,va>变成<(5,ka),va>。
B表每一条数据都复制10份,每一个数据都带有一个随机数<kb,vb>变成<(1,kb),vb>,<(2,kb),vb>...等等。
因此A join B。相当于A被打散了,最终输出key相同数据，原来要求ka=kb,现在要求(5,ka)=(5,kb)。

2.优缺点分析:
适用场景:一个数据集存在的倾斜Key比较多，另外一个数据集数据分布比较均匀。
并且一个表大,一个表相对来说小,但也不足放在内存里。如果两个表都很大,则不适用于该方法。因为对任何一个大表扩大N倍都是不行的。
优势:对大部分场景都适用，效果不错。
劣势:需要将一个数据集整体扩大N倍，会增加资源消耗。

3.继续优化空间:只对倾斜的key做扩大，而不是对全表做扩大，即A表只对倾斜的key做随机，B表只对倾斜的key做扩大倍数。这样倍数可以扩大的大一些，比如100倍，程序更散列。
问题是如何确定打key是谁？需要有一个统计程序,跑出来统计的结果。

三、解决方案:拆分 join 再 union
思路很简单，就是将一个 join 拆分成 倾斜数据集 Join 和 非倾斜数据集 Join，最后进行 union:
对包含少数几个数据量过大的 key 的那个 RDD (假设是 leftRDD)，通过 sample 算子采样出一份样本来，然后统计一下每个 key 的数量，计算出来数据量最大的是哪几个 key。具体方法上面已经介绍过了，这里不赘述。
然后将这 k 个 key 对应的数据从 leftRDD 中单独过滤出来，并给每个 key 都打上 1~n 以内的随机数作为前缀，形成一个单独的 leftSkewRDD；而不会导致倾斜的大部分 key 形成另外一个 leftUnSkewRDD。
接着将需要 join 的另一个 rightRDD，也过滤出来那几个倾斜 key 并通过 flatMap 操作将该数据集中每条数据均转换为 n 条数据（这 n 条数据都按顺序附加一个 0~n 的前缀），形成单独的 rightSkewRDD；不会导致倾斜的大部分 key 也形成另外一个 rightUnSkewRDD。
现在将 leftSkewRDD 与 膨胀 n 倍的 rightSkewRDD 进行 join，且在 Join 过程中将随机前缀去掉，得到倾斜数据集的 Join 结果 skewedJoinRDD。注意到此时我们已经成功将原先相同的 key 打散成 n 份，分散到多个 task 中去进行 join 了。
对 leftUnSkewRDD 与 rightUnRDD 进行Join，得到 Join 结果 unskewedJoinRDD。
通过 union 算子将 skewedJoinRDD 与 unskewedJoinRDD 进行合并，从而得到完整的 Join 结果集。
（1）适用场景
两张表都比较大，无法使用 Map 端 Join。其中一个 RDD 有少数几个 Key 的数据量过大，另外一个 RDD 的 Key 分布较为均匀。
（2）解决方案
将有数据倾斜的 RDD 中倾斜 Key 对应的数据集单独抽取出来加上随机前缀，另外一个 RDD 每条数据分别与随机前缀结合形成新的RDD（相当于将其数据增到到原来的N倍，N即为随机前缀的总个数），
然后将二者Join并去掉前缀。然后将不包含倾斜Key的剩余数据进行Join。最后将两次Join的结果集通过union合并，即可得到全部Join结果。
（3）优势
相对于 Map 则 Join，更能适应大数据集的 Join。如果资源充足，倾斜部分数据集与非倾斜部分数据集可并行进行，效率提升明显。且只针对倾斜部分的数据做数据扩展，增加的资源消耗有限。
（4）劣势
如果倾斜 Key 非常多，则另一侧数据膨胀非常大，此方案不适用。而且此时对倾斜 Key 与非倾斜 Key 分开处理，需要扫描数据集两遍，增加了开销。

