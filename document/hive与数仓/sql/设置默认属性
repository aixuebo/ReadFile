综合配置
SET spark.memory.fraction=0.7;
SET spark.yarn.executor.memoryOverhead=1024;
SET spark.executor.cores=1;

SET spark.executor.memory=16g;
SET spark.driver.memory=16g;

SET hive.exec.dynamic.partition.mode=nonstrict;
SET hive.exec.dynamic.partition=true;
SET hive.exec.max.dynamic.partitions=1000;
## 触发spark合并小文件的阈值(1M)
SET spark.sql.mergeSmallFileSize=5048576;
## 小文件合并参数
SET spark.hadoopRDD.targetBytesInPartition=67108864;
SET spark.sql.adaptive.shuffle.targetPostShuffleInputSize=134217728;

## spark shuffle默认分区数
SET spark.sql.shuffle.partitions=50;


一、设置reduce数量
set mapred.reduce.tasks = 5;

注意:
1.一定要在-------------之前设置,否则会抛异常
2.set mapred.reduce.tasks = 5;前面一定不能是-----,否则会说解析语法错误,就直接设置set mapred.reduce.tasks = 5;即可

hive <<EOF

set mapred.reduce.tasks = 5;

-------------
sql

quit;
EOF

二、自动map端join优化
set hive.auto.convert.join = true;
set hive.mapjoin.smalltable.filesize = 30000000.  30M
默认是开启join在map端自动优化功能的,但是有时候会因为内存不够,导致出现 java.lang.OutOfMemoryError: GC overhead limit exceeded
因此有时候需要将其关闭掉,即set hive.auto.convert.join = false;

一般出现的异常输出提示是:Starting to launch local task to process map join;      maximum memory =
导致重试很多次map端在本地执行任务,都失败,失败次数超过了一定伐值,因此任务fault,没有reduce输出产生。
  

三、设置引擎是tez
set hive.execution.engine=tez;


四、设置hive的执行名字
set mapred.job.name='topic_order-detail-1-${create_time}';
五、设置hive的输出文件后缀
set hive.output.file.extension=.c1;

六、设置动态分区
a.
set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nostrick;
set hive.exec.max.dynamic.partitions=5000 最大的分区数量
set hive.exec.max.dynamic.partitions.pernode=2000

b.insert overwrite table dim.topic_user_partition partition(log_day)
c.select的最后几个字段的值就是分区的值

七、set hive.mapred.mode=nostrict; 取消hive的约束,即查询分区表的时候,如果不写分区字段,也是允许执行的

八、更换队列
set mapreduce.job.queuename=xstorm;

九、为结果生成title
set hive.cli.print.header=true;

十、hive.exec.parallel
默认是false,将其设置为true,可以让一个sql中包含的多个job,而很多job是没有关系的，可以同时执行，但是缺点是消耗更多的资源。
比如
select r1.a
from (
   select t.a from sunwg_10 t join sunwg_10000000 s on t.a=s.b) r1 
   join 
   (select s.b from sunwg_100000 t join sunwg_10 s on t.a=s.b) r2 
   on (r1.a=r2.b);
但是可以看出来其实两个子查询中的sql并无关系,可以并行的跑

十一、设置让presto使用hive的窗口函数语法
set compatible.grammar=sparksql;

十二、增加FetchWaitTime时间，当shuffle数据量大的时候，会超时，所以需要修改该参数
SET spark.shuffle.maxFetchWaitTime=7200s;
set spark.shuffle.manager=rss;

十三、配置默认cu和内存数
SET spark.memory.fraction=0.7;
SET spark.yarn.executor.memoryOverhead=1024;
SET spark.executor.cores=1;

配置内存
SET spark.executor.memory=16g;
SET spark.driver.memory=16g;

十四、通用配置
set mapred.job.name='job名称';
SET mapreduce.job.queuename=root.xxxx队列名称;
set hive.mapred.mode=nostrict;
set hive.auto.convert.join = false;
set hive.exec.parallel=true;
set mapred.reduce.tasks = 5;

十五、重新分配partition数量。
如果上游hive表本身就很少的分区数量，在cube执行过程中就会并发小，执行慢，需要手动调高并发度。

## spark shuffle默认分区数
SET spark.sql.shuffle.partitions=500;

        from
        (
            select *
            from biao
            distribute by cast(rand()*300 as int) ### 手动调大300个分区
        ) t
十六、小文件merge
若检测到小文件过多，可参考以下几种常见措施进行优化：
## 触发spark合并小文件的阈值(1M)
SET spark.sql.mergeSmallFileSize=5048576;
## 小文件合并参数
SET spark.hadoopRDD.targetBytesInPartition=67108864;
SET spark.sql.adaptive.shuffle.targetPostShuffleInputSize=134217728;

1、当执行的作业没有shuffle阶段，即只有map task，没有reduce task，或者希望每个map task能处理更大的数据量时，可以设置如下参数：
set spark.hadoopRDD.targetBytesInPartition=67108864;(默认为33554432)；
2、 当执行的作业存在shuffle阶段，即存在reduce task，希望最后输出的文件数比较少，或者每个reduce task写的单个文件更大时，可以设置如下参数：
set spark.sql.adaptive.shuffle.targetPostShuffleInputSize=134217728;(默认67108864，64M)。
