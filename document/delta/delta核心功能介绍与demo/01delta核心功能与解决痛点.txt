一、背景与总结


二、解决痛点
1.hive等引擎,存储数据不是原子的，所以查询之间不存在隔离。
例如，如果一个查询需要更新表中的多个对象，那么我们查询的时候可以看到数据一部分更新了，一部分没有更新。
2.对于具有数百万个对象的大表，元数据操作的开销很大
例如，Parquet 文件在页脚部分包含最小/最大统计信息，查询的时候可以利用这些信息跳过一些不用的文件。
在 HDFS 上读取这些文件的页脚信息可能要花费几毫秒，但是云对象存储的延迟要高得多，甚至读取这些统计信息以便跳过一些不必要读取的文件可能比实际查询花费更长的时间。
3.节省空间
传统的数仓,都是基于dt的快照形式存储，而不是基于系统已发生的binlog日志存储，造成数据存储空间的浪费。
(当然流量表这种快照存储的本身就是增量数据的场景，没有节省空间)。

三、提供的功能 -- 核心通过事务做底层基建
1.时间旅行Time travel，这个特性可以让用户查询给定时间点的快照或回滚错误更新到之前正确的数据。
可以支持数据恢复能力。
2.高效的流 IO：通过让流作业以低延迟的形式将小对象写入表中，然后以事务形式将它们合并到较大的对象中以提高查询性能。
3.支持delete、update、merge操作。避免hive只有drop分区、insert单一功能。
4.模式演变：如果表的模式发生变化，Delta 可以继续读取旧的 Parquet 文件而无需重写它们。
5.审计日志：基于事务日志的审计功能。

