一、背景与总结
1.背景
delta构建在spark上,所以会面临多个任务同时读取delta的存储表、多个任务同时写delta的存储表(可能同时写入同一个分区的场景)。
如何适中面向用户显示正确的数据，完全依赖事务日志(deltaLog),即json文件的顺序性。


二、多并发写入时，delta如何设计的
1.由于Delta由Apache Spark提供支持，因此不仅可以让多个用户同时修改表 - 这是预期的。为了处理这些情况，Delta Lake 采用了乐观的并发控制。
2.什么是乐观并发控制？
乐观并发控制是一种处理并发事务的方法，他假设不同用户操作同一个表所做的内容是可不冲突的情况下完成的，因此他是可以支持并发写入的，并且在处理PB级的数据时，多个操作都是处理不同的数据，因此并发可以让其更高效的完成。
比如 类似玩拼图，多个人，每个人拼的都是不同的角落，肯定是可以一起高效的合作完成任务的。这就是乐观并发控制。(无锁,所以效率高)

实现方案: 背景：A用户向表新增一条数据；同时B也新增一条数据。两者都是append追加操作。
a.每一个用户操作前，delta都会记录操作前数据的版本号，比如当前版本是0.
b.两个用户都append数据，此时会有冲突，即不知道谁先提交，将其提交内容写入到000001.json里。
由于都是append操作，因此delta会随意找一个用户，将其结果写到000001.json里，此时另外一个用户操作失败。
c.操作失败的用户，不会返回给客户端，告知失败，而是继续乐观操作。
他会悄悄的再次提交000002.json.

3.如果不同用户处理同一个数据修改/删除，那就不会发生乐观的并发控制了。
在绝大多数情况下，这种和解是悄无声息地、天衣无缝地、成功地进行乐观操作的。
但是，如果 Delta Lake 无法乐观地解决不可调和的问题(例如，如果用户1删除了用户2也删除的文件)，那么惟一的选择就是抛出一个错误。


4.支持的核心原理是append操作
a.整个delta平台依赖事务json文件顺序，确定数据的顺序，保证了数据的稳定一致性。
至于并发时，哪个任务先保存到json中，完全由明确的逻辑规则确定即可。
b.Delta Lake 支持并发读取和仅追加写入(append-only)。要被视为只追加数据，写入者必须只添加新数据，而不以任何方式读取或修改现有数据。允许并发读取和追加，即使在相同的 Delta 表分区上操作，也可以获得快照隔离。

三、核心内容都在OptimisticTransaction里。


四、版本控制冲突的异常方式
多个job可以并发的操作，可能会造成同一个分区被多个job都有修改，所以造成的冲突，此时冲突是无法修复的，只能失败，让客户端重新提交。
并发操作的概念是 job1执行任务，job2也同时执行任务，job1写入到json中；job2也写入到json中。此时只能有一个顺序，按照顺序生产json文件。如果顺序之间存在冲突，则第一个成功，剩下的job都要失败。
失败的场景如下:
1.ConcurrentAppendException 有job向分区内添加文件，而其他job读取了该分区的内容。此时分区内容已经发生变化，其他job读取的内容是有脏数据的，所以要抛出异常,job失败。
ConcurrentDeleteReadException 同理有job删除分区内的数据，而其他job读取了该分区的内容。带来的job失败。
2.ConcurrentDeleteDeleteException 当job1删除了分区的某一个文件，而job2也删除了某一个文件，此时会抛异常,job失败。
3.MetadataChangedException 多个job都同时触发了ALTER TABLE，因此只能有一个job成功，其他job都会失败。
4.ProtocolChangedException 一个job升级了，其他job肯定要失败，基于新升级后的版本再重新提交任务。
5.ConcurrentTransactionException 这个没太理解。
如果使用相同检查点位置的流式处理查询同时启动多次，并尝试同时写入Delta表。 永远不应让两个流式处理查询使用相同的检查点位置并同时运行。

五、生产系统是如何避免并发冲突的。
1.正常hive表操作，也都是只有一个任务在做写入操作。
通过任务的调度控制的。所以理论上也可以通过业务规则，避免任务的并发写入场景。