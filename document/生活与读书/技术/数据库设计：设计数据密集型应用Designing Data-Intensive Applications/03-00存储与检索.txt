一、背景与总结

二、数据库提供的基础能力 --- set/get
1.set
db_set key value
2.get
db_get key
3.方案对比
set函数，要求高效，即往文件尾部顺序追加即可。
get函数，也要求高效，但在尾部追加的实现中，同样的key也是重复追加，因此get需要找到所有满足条件的key后，获取最新的一条数据返回；此时遍历复杂度是O(n),查询效率取决于数据体量。
4.索引index
提高查找数据的能力，存储额外的信息，即非主键的key组合与id主键的映射关系。方便快速定位到id的offset位置，快速访问该id信息。
索引写入的性能是有损耗的，因为他不是顺序追加写入，而是要不断影响索引结构。因此增加索引越多，插入性能越慢(本来插入是顺序插入，性能极高)。
所以存储系统的权衡是 索引加快查询速度 与 索引拖慢写入速度之间的平衡。

三、散列表+不断文件追加写入的实现 注意细节
1.散列索引
假设数据库是kv数据库，并且是追加方式写入的数据。
在内存里维护一个map散列索引，每次写入数据后，更新散列索引，即每一个key在文件中的偏移量。
这种架构的存储引擎，非常适合经常更新的key-value数据库；
缺点也很明显，就是索引在内存里，很多场景索引的key很多的时候，内存是存不下的。

2.数据文件如何优化
一直不断写入，会造成磁盘满了。
解决方案：将日志按照大小、周期的方式，切分成段（segment），当满足段的尺寸后，关闭段，打开新的段，开始写入数据。
多个段还可以进行压缩（compaction），将日志中丢弃重复的键，只保留每个键的最近更新。
即压缩单独段，单独段内key重复的会被丢弃，文件变小；压缩多个段，也会变小。

段是不会更新的，merge创新的段，删除老的段。因此可以再后台线程完成段的压缩。
压缩未完成时，继续使用旧段提供读写请求。合并完成后，将读写请求转换为新段读写，删除旧数据即可。

3.数据查询
每个段现在都有自己的内存散列表，将键映射到文件偏移量。
为了找到一个键的值，我们首先检查最近的段的散列映射；
如果键不存在，我们就检查第二个最近的段，
依此类推。合并过程将保持段的数量足够小，所以查找过程不需要检查太多的散列映射。

4.数据删除
删除一个key,则只需要在文件追加key-value后，追加一个删除标记(墓碑，即 tombstone)。因此当段合并的时候，就会删除历史前所有该key的数据。

5.崩溃恢复
内存中的散列表会消失，原则上可以通过读取段，来恢复散列表。
但如果段很大，恢复进度很慢，导致重启服务很慢，长时间无法线上提供服务。
解决方案，将每一个段的散列表序列化，这样可以直接读取序列化的结果，直接加速恢复。

6.崩溃造成的数据写入问题。
文件包含校验和，允许检测和忽略日志中的这些损坏部分。

7.并发控制
由于写操作是以严格的顺序追加到日志中的，所以常见的实现是只有一个写入线程。也因为数据文件段是仅追加的或者说是不可变的，所以它们可以被多个线程同时读取。

8.缺点
a.散列表必须能放进内存。
原则上可以在硬盘上维护一个散列映射，不幸的是硬盘散列映射很难表现优秀。它需要大量的随机访问 I/O，而后者耗尽时想要再扩充是很昂贵的，并且需要很烦琐的逻辑去解决散列冲突。
b.范围查询效率不高。
例如，你无法轻松扫描 kitty00000 和 kitty99999 之间的所有键 —— 你必须在散列映射中单独查找每个键。

四、SSTables和LSM树
1.背景
在第三部分中，key-value存储引擎中，每一个key-value是追加的方式写入文件的，并且保障以最后一次key对应的value为准。
有点是写入性能高，缺点是查询性能慢，但可以通过定期段的merge做优化。外加每一个段有hash索引。
但我们考虑另外一种存储解法，更改一下存储结构，让存储的数据不再是追加的，而是key按照一定规则排序后的。

2.排序字符串表（Sorted String Table,简称SSTable)，即打破了文件按照顺序写入的规则。
a.每一个文件段内的数据,key要排序后存储。
b.key只能在每一个段内仅出现一次。即最新值即可，随时丢弃无效数据。

3.SSTable优势
a.合并段使用归并排序,是非常高效的，并且不受内存限制，段文件再大也可以merge成功。
多个文件一起读，获取最小的key,输出到新的merge文件中，此时merge文件的key天然也是排序好的。
b.如果多个段中有相同的key,按照时间顺序，保留最新的值即可。
c.get方法,不需要内存保留所有的key散列索引,而是保存跳表的key即可，从最接近跳表中的key开始扫描段文件内容即可。要么找到，要么找不到返回null。
d.将段内部做更小的block块拆分，每一个块的第一个key以及此时块在文件中的位置所谓散列索引。即每一个block块存储1000个key-value。每1000个key做为散列表的一个数据。
每一个block可以单独压缩，节省磁盘空间，同时也减少了网络IO传输的带宽,客户端下载压缩后的数据,在反序列化查找key。

4.构建和维护SSTables
内存保存有序结构是很容易的，比如红黑树或 AVL 树。
使用B树的结构,在硬盘上维护有序数据结构。

新增步骤如下:
a.创建内存表（memtable）：新增一条数据，添加到内存平衡树种。
b.创建SSTable文件:内存大于阈值,物化到硬盘。此时有序的内存结构存储到磁盘是很高效的。
c.在写入硬盘时，可同时开启新的内存,接收新的数据。

读取步骤如下:
a.查询内存表是否命中key,命中则返回。
b.从最后一个SSTable文件开始查找，以此类推，找到第一次出现的key为止。
查找过程可以是每一个SSTable文件内部有数据块block索引。


后台进程:合并段文件，并且删除旧的段文件。

存在问题：如果数据库崩溃，则最近的写入（在内存表中，但尚未写入硬盘）将丢失。
解决方案：追加的log日志,用于崩溃恢复。
每当内存表写出到 SSTable 时，相应的日志都可以被丢弃。

5.用SSTables制作LSM树(日志结构合并树)
LSM树就是对SSTables文件集合进行封装，自动后台做合并。对外整体体现是一颗文件树。
由于文件内本身是按照顺序存储的，因此可以高效执行范围查询。
并且因为硬盘写入是连续的，所以 LSM 树可以支持非常高的写入吞吐量。

本质上是LevelDB和RocksDB中key-value存储引擎使用的技术。
a.性能优化
如果查找数据库中不存在的key,则LSM中查找性能会很差，他会先查内存，在查所有的段文件，然后才能确定key不存在。
解决方案，将所有的key存放在布隆过滤器中。

b.合并策略
不同策略，决定了合并SSTables的顺序以及时间。
最常见的选择是 size-tiered 和 leveled compaction
a.对于 sized-tiered，较新和较小的 SSTables 相继被合并到较旧的和较大的 SSTable 中
b.对于 leveled compaction，key （按照分布范围）被拆分到较小的 SSTables，而较旧的数据被移动到单独的层级（level），这使得压缩（compaction）能够更加增量地进行，并且使用较少的硬盘空间。
LevelDB 和 RocksDB 使用 leveled compaction（LevelDB 因此得名）
HBase 使用 size-tiered。

五、B树
1.使用最广泛的索引结构 与 前面讨论的 日志结构索引完全不同。
日志结构索引，常用于大数据组件。
B树常用于关系型数据库的索引，比如mysql。

2.特点
a.日志索引的段是可变大小的,通常是几M，B树是固定大小的块(block)或者页(page)，通常是4k。一次只能读取一整个page。
每一个page都用地址位置来标识，在内存中一个page引用另外一个page，因此内存构建了一个页面page树。
大概的数据结构 <pageID,offset,nextPageID>
b.每一个pageID的内容是排序好的。
因此定位到某一个page_id后，可以知道offset偏移量，直接读取数据。同时范围查找nextPageID，即可读取下一个页的有序信息，所以范围检索很快。
c.本质上是一颗二叉树，所以查询性能会很快。
B树根节点是一个page.里面存储了几个key以及对应的page引用.下游每一个子页面都负责一段连续的范围的key。
正常来说B树的一个page上大概有几百个key，考虑的是树的深度和查询性能的平衡。
大多数数据库可以放入一个三到四层的 B 树，所以你不需要追踪多个页面引用来找到你正在查找的页面（分支因子为 500 的 4KB 页面的四层树可以存储多达 256TB 的数据。
d.索引就是如果根据key集合，锁定到某一个page_id。

3.新增索引数据:
找到对应的page,在page内排序，追加到合适的位置。
如果page空间不足，则拆分成两个page。更新父page，以反映新的键范围分区。

4.索引更新:
找到key对应的page，更新,写会到磁盘。(因为按照key排序,所以更新值并不影响page,除非更新的值太大，超过了page的范围，此时需要拆分成2个page,更新父page操作)

5.让B树更可靠
a.B树的更新操作和写入操作，都假定的是不改变page位置为前提。更新内容，物化到磁盘。
但事实上可能会存在一次写入多个page的情况，比如插入导致页面过满而拆分页面，则需要写入新拆分的两个页面，并覆写其父页面以更新对两个子页面的引用。
这是一个危险的操作，因为如果数据库在系列操作进行到一半时崩溃，那么最终将导致一个损坏的索引（例如，可能有一个孤儿页面没有被任何页面引用） 。
b.预写式日志（WAL，即 write-ahead log，也称为 重做日志，即 redo log）。
先追加日志，当数据库在崩溃后恢复时，这个日志将被用来使 B 树恢复到一致的状态。
c.还有一个更新页面的复杂情况是，如果多个线程要同时访问 B 树，则需要仔细的并发控制 —— 否则线程可能会看到树处于不一致的状态。这通常是通过使用 锁存器（latches，轻量级锁）保护树的数据结构来完成。
d.B树的优化
①.尽量使叶子页面按顺序出现在硬盘上,防止多次硬盘查找。
②.额外的指针添加到树中，比如每个叶子页面可以引用其左边和右边的兄弟页面，使得不用跳回父页面就能按顺序对键进行扫描。


六、比较B树和LSM树
1.简单对比
a.LSM树写入速度快。B树的读取速度更快。
LSM 树上的读取通常比较慢，因为它们必须检查几种不同的数据结构和不同压缩（Compaction）层级的 SSTables。

2.LSM树优点
a.LSM 树通常能够比 B 树支持更高的写入吞吐量，因为它们顺序地写入紧凑的 SSTable文件而不是必须覆写树中的几个页面。
b.LSM 树可以被压缩得更好，因此通常能比 B 树在硬盘上产生更小的文件。

3.LSM树的缺点
a.压缩出现在高写入吞吐量时：硬盘的有限写入带宽需要在初始写入（记录日志和刷新内存表到硬盘）和在后台运行的压缩线程之间共享。
如果写入吞吐量很高，并且压缩没有仔细配置好，有可能导致压缩跟不上写入速率。在这种情况下，硬盘上未合并段的数量不断增加，直到硬盘空间用完，读取速度也会减慢，因为它们需要检查更多的段文件。
b.压缩的时候，可能会占用较高CPU，没有资源进行读操作。
c.事务能力弱。
B树优点是一个key只存在某一个页中，而不是像日志结构一样存储在多个段文件中。因此B树可以提供更强大的事务语义操作。

七、其他索引结构
1.主键索引
key,以及对应的文件offset，从而可以快速读取数据。(数据也可以从内存直接读取)
2.次级索引
key对应的主键索引key，通过二次查询主键key找到对应的文件offset，从而读取数据。
3.聚集索引（clustered index） --- 将值存储在索引中
避免索引key读取的是位置信息，还需要一次读取，而如果具体的一行内容或者关键内容都存储在索引里，那就不需要二次扫描了，效率会更高，
当然索引也会更大，看看索引查询效率与存储是评分标准。
聚集索引：将被索引的行直接存储在索引中，比如MySQL 的 InnoDB中，表的主键就是一个聚集索引，因为主键id作为key存储，索引本身就可以获取到主键信息。
4.多列索引 -- 对多个列按照固定顺序，索引。
核心问题是只能解决按照顺序查找的场景。
5.多维索引（multi-dimensional index）
比如:
SELECT * 
FROM restaurants 
WHERE latitude > 51.4946 AND latitude < 51.5079
AND longitude > -0.1162 AND longitude < -0.1004;

解决方案:
a.空间填充曲线（space-filling curve） 将二维位置转换为单个数字，然后使用常规 B 树索引。
b.更普遍的是，使用特殊化的空间索引，例如 R 树。
6.全文搜索和模糊索引 -- trie。
7.在内存中存储一切
a.将它们全部保存在内存中是非常可行的，包括可能分布在多个机器上。这导致了内存数据库的发展。
b.Redis 和 Couchbase 通过异步写入硬盘提供了较弱的持久性。因此他们不算是真正意义的内存数据库，因为不支持强持久化能力。
c.内存数据库的优势。
提供了难以用基于硬盘的索引实现的数据模型。
例如，Redis 为各种数据结构（如优先级队列和集合）提供了类似数据库的接口。因为它将所有数据保存在内存中，所以它的实现相对简单。
d.反缓存
内存数据库体系结构可以扩展到支持比可用内存更大的数据集，而不必重新采用以硬盘为中心的体系结构
所谓的 反缓存（anti-caching） 方法通过在内存不足的情况下将最近最少使用的数据从内存转移到硬盘，并在将来再次访问时将其重新加载到内存中。
尽管如此，这种方法仍然需要索引能完全放入内存中（就像本章开头的 Bitcask 例子）。
