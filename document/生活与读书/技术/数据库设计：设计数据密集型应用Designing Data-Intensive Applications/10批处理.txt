一、背景与总结


二、排序 VS 内存中的聚合
1.区别
a.内存聚合,内存使用hash方式存储所有的key与计数结果。
b.排序,不消耗内存，这与我们在 “SSTables 和 LSM 树” 中讨论过的原理是一样的：数据块可以在内存中排序并作为段文件写入磁盘，然后多个排序好的段可以合并为一个更大的排序文件。 归并排序具有在磁盘上运行良好的顺序访问模式。
linux的sort命令，就是程序通过溢出至磁盘的方式来自动应对大于内存的数据集，并能同时使用多个 CPU 核进行并行排序【9】。这意味着我们之前看到的简单的 Unix 命令链很容易伸缩至大数据集，且不会耗尽内存。瓶颈可能是从磁盘读取输入文件的速度。

2.Unix哲学的借鉴
a.让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加 “功能” 让老程序复杂化。
b.期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。

统一的接口的价值
unix如何做到每一个程序之间交互的？为什么下一个程序的输入，就能理解上一个程序的输出？完全靠的就是统一接口。
在 Unix 中，这种接口是一个 文件（file，更准确地说，是一个文件描述符）。
一个文件只是一串有序的字节序列。每一个程序都去读取文件，按照协商好的或者默认的分隔符拆分成字段即可。

Unix 工具的最大局限在于它们只能在一台机器上运行 —— 而 Hadoop 这样的工具即应运而生。

三、MapReduce和分布式文件系统
1.执行步骤
a.Map是将代码复制到数据节点，然后再数据节点执行代码。
b.Map任务的数量由输入文件块的数量决定。
reduce的数量由作者配置。
c.为了确保具有相同键的所有键值对最终落在相同的 Reducer 处，框架使用键的散列值来确定哪个 Reduce 任务应该接收到特定的键值对。
d.map端需要对key排序，但数据集可能太大，无法在单台机器上使用常规排序算法进行排序。所以类似“SSTables 与 LSM 树” 中讨论的，分批内存排序，然后磁盘merge。
e.reduce在map拉去数据，由于reduce需要去所有的mapper拉去数据，所以会发生大量的网络IO，此时称为shuffle。
虽然每一个mapp上拉去的数据是有序的，但reduce需要做merge，确保每一个key在所有的map的结果是全局有序。
f.reduce对结果输出，该结果为下一个map的输入。

四、如何处理数据倾斜
1.Pig 中的 偏斜连接（skewed join）
a.运行一个抽样作业（Sampling Job）来确定哪些键是热键。
b.连接实际执行时，Mapper 会将热键的关联记录 随机发送到几个 Reducer 之一。
c.对于另外一侧的连接输入，与热键相关的记录需要被复制到 所有 处理该键的 Reducer 上。
这样可以使其更好地并行化，代价是需要将连接另一侧的输入记录复制到多个 Reducer 上。 

2.Hive采取了另一种方法。它需要在表格元数据中显式指定热键，并将与这些键相关的记录单独存放，与其它文件分开。
当在该表上执行连接时，对于热键，它会使用 Map 端连接。

当按照热键进行分组并聚合时，可以将分组分两个阶段进行。第一个 MapReduce 阶段将记录发送到随机 Reducer，以便每个 Reducer 只对热键的子集执行分组，为每个键输出一个更紧凑的中间聚合结果。
然后第二个 MapReduce 作业将所有来自第一阶段 Reducer 的中间聚合结果合并为每个键一个值。

五、Map端join
1.广播散列连接
可以是内存，也可以利用磁盘+索引的方式，相当于每一个节点有一个小型数据库。
2.分区散列连接在 Hive 中称为 Map 侧桶连接（bucketed map joins）
这种方法只有当连接两端输入有相同的分区数，且两侧的记录都是使用相同的键与相同的哈希函数做分区时才适用。
Mapper3 首先将所有具有以 3 结尾的 ID 的用户加载到散列表中，然后扫描 ID 为 3 的每个用户的所有活动事件。

六、应用
1.Lucene原理：
一个文件，存储关键词与包含该关键字的所有文档 ID 列表映射。
a.全量更新：每天定时跑任务。
b.增量更新：对于增量的数据，创建索引，后台异步的对新索引和历史索引丛merge。

2.hive缺点，为什么要偏向用spark和flink
hive缺点:
MapReduce 作业只有在前驱作业中的所有任务都完成时才能启动。
Mapper 通常是多余的：它们仅仅是读取刚刚由 Reducer 写入的同样文件，为下一个阶段的分区和排序做准备。在许多情况下，Mapper 代码可能是前驱 Reducer 的一部分：如果 Reducer 和 Mapper 的输出有着相同的分区与排序方式，那么 Reducer 就可以直接串在一起，而不用与 Mapper 相互交织。

spark的优点：
排序等昂贵的工作只需要在实际需要的地方执行，而不是默认地在每个 Map 和 Reduce 阶段之间出现。
map任务不需要直接对接reduce进行shuffle，如果不需要shuffle，则可以让reduce的结果进一步reduce。
算子之间的数据可以再内存或者本地磁盘里，比写入HDFS作为中间态的hadoop要节省性能。
算子之间的不需要等待上游算子结束，而是可以一同进行。即第一个算子对一条数据处理完后，第二个算子就可以进行处理，不需要等待第一个算子把所有数据源都处理完成。(注意:排序算子不可避免地需要消费全部的输入后才能生成任何输出)。

