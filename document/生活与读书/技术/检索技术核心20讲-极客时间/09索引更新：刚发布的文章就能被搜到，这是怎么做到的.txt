一、背景与总结
1.虽然使用了分布式map-reduce的方式构建索引，但对于超大规模的网页建立索引会非常耗时。
对于发布较久的网页，搜索引擎可以有充足的时间来构建索引。但是一些新的网页和文章，往往发布了几分钟就可以被用户搜索到。这又是怎么做到的呢？今天，我们就来聊一聊这个问题。


二、工业界如何更新内存中的索引？
我们先来看这么一个问题：如果现在有一个小规模的倒排索引，它能完全加载在内存中。当有新文章进入内存的时候，倒排索引该如何更新呢？这个问题看似简单，但是实现起来却非常复杂。

1.方案
找到term对应的文章ID集合，插入新增的文档集合即可。

2.遇到的问题
多用户同时操作一个数据，有读写锁问题，因此在更新时，要加锁，但整个系统的检索效率会比无锁状态有所下降。

3.解决问题
在工业界的实现中，我们会使用一种叫做“Double Buffer（双缓冲）机制”的解决方案，使得我们可以在无锁状态下对索引完成更新。

即在内存里同时存在2套一样的索引,A和B。
一个读指针指向索引A，表示A当前可读，因此来读请求时，都去A索引查数据。
而写请求时，都是更新索引B。
当B更新完成后，使用原子操作，把指针从A移动到B，因此下一个请求读B，写A。同时把刚刚更新B的数据更新到A里。

因此在无锁的状态下，高效的完成了更新索引。

不过，为了避免切换太频繁，我们并不是每来一条新数据就更新，而是积累一批新数据以后再批量更新。

4.代价
内存要两份，浪费内存空间。
为了避免内存数据丢失，索引不同步，可以使用LSM树方式，先记录log，顺序写入磁盘问题做兜底。可以参考07节课程原理。

三、如何使用“全量索引结合增量索引”方案？
对于大规模的索引更新，工业界常用“全量索引结合增量索引”的方案来完成。
即 全量索引 + 增量索引 - 删除索引数据

1.方案
第一，系统会周期性地处理全部的数据，生成一份完整的索引，也就是全量索引。
这个索引不可以被实时修改，因此为了提高检索效率，我们可以不加“锁”。

第二,我们会将新接收到的数据单独建立一个可以存在内存中的倒排索引，也就是增量索引。
当查询发生的时候，我们会同时查询全量索引和增量索引，将合并的结果作为总的结果输出。这就是“全量索引结合增量索引”的更新方案。

第三,使用Double Buffer机制对增量索引进行索引更新。
这样一来，增量索引就可以做到无锁访问。
而全量索引本身就是只读的，也不需要加锁。
因此，整个检索过程都可以做到无锁访问，也就提高了系统的检索效率。

第四,删除的数据，添加到“删除列表”中,
检索的时候，如果结果数据存在于删除列表中，就说明该数据是无效的，我们直接删除它即可。

四、增量索引空间的持续增长如何处理？
内存毕竟有限。如果我们不对内存中的增量索引做任何处理，那随着时间推移，内存就会被写满。因此，我们需要在合适的时机将增量索引合并到全量索引中，释放增量索引的内存空间。
将增量索引合并到全量索引中的常见方法有3种，分别是：完全重建法、再合并法和滚动合并法。

1. 完全重建法
如果增量索引的增长速度不算很快，或者全量索引重建的代价不大，那么我们完全可以在增量索引写满内存空间之前，完全重建一次全量索引，然后将系统查询切换到新的全量索引上。

2. 再合并法
增量索引 + 全量索引，采用归并排序的方式，merge生成新的全量索引。
这也就避免了从头处理所有文档的重复开销。

3. 滚动合并法
a.如果全量索引和增量索引的量级差距过大，那么再合并法的效率依然不高。
为什么这么说呢？我们以搜索引擎为例来分析一下。在搜索引擎中，增量索引只有上万条记录，但全量索引可能有万亿条记录。
这样的两个倒排索引合并的过程中，只有少数词典中的关键词和文档列表会被修改，其他大量的关键词和文档列表都会从旧的全量索引中被原样复制出来，
再重写入到新的全量索引中，这会带来非常大的无谓的磁盘读写开销。
因此，对于这种量级差距过大的全量索引和增量索引的归并来说，如何避免无谓的数据复制就是一个核心问题。

b.最直接的解决思路就是原地更新法。所谓“原地更新法”，就是不生成新的全量索引，直接在旧的全量索引上修改。
但这种方法在工程实现上其实效率并不高，原因有两点。

首先，它要求倒排文件要拆散成多个小文件，每个关键词对应的文档列表为一个小文件，这样才可以将增量索引中对应的变化直接在对应的小文件上单独修改。
但这种超大规模量级的零散小文件的高效读写，许多操作系统是很难支持的。

其次，由于只有一份全量索引同时支持读和写，那我们就需要“加锁”，这肯定也会影响检索效率。
因此，在一些大规模工程中，我们并不会使用原地更新法。

c.优化方案
滚动合并法，就是先生成多个不同层级的索引，然后逐层合并。

比如说，一个检索系统在磁盘中保存了全量索引、周级索引和天级索引。
所谓周级索引，就是根据本周的新数据生成的一份索引，那天级索引就是根据每天的新数据生成的一份索引。

假设最小单位是天，那么每天的数据，做一个并归排序merge。
由于天级的索引文件条数远远没有全量索引多，因此这不会造成大量的无谓数据复制。

等系统中积累了7天的天级索引文件后，我们就可以将这7个天级索引文件合并成一个新的周级索引文件。
因此，在每次合并增量索引和全量索引的时候，通过这样逐层滚动合并的方式，就不会进行大量的无谓数据复制的开销。这个过程就叫作滚动合并法。

d.我自己想到的实现方案
数据进来后，使用Double Buffer机制，先存放在内存中，内存是2份相同的数据。 ---> 记作A和B
内存达到阈值后，新开放一块内存，存储新增的数据。---> 记作C和D
此时A和B其实是相同的内容，并且不会变化了，因此将任意一个存储带磁盘即可。然后清空内存。---> 记作E。
然后C和D达到阈值后，重新内存新增区域A和B，进行写入数据。然后C提供读，D+E进行读取+并归merge操作，产生F。原子操作删除E。

