一、背景与总结
1.通常来说，用一张大表去关联另一张大表，这种做法在业内是极其不推荐的。甚至毫不客气地说，“大表Join大表”是冒天下之大不韪，犯了数据分析的大忌。
如果非要用“大表Join大表”才能实现业务逻辑、完成数据分析，这说明数据仓库在设计之初，开发者考虑得不够完善、看得不够远。

2.感觉这个case案例并不是非常好,没有彻底的解决该问题。
核心问题是多次扫描主表问题没有解决的非常完美。

二、如何理解“分而治之”？
“分而治之”的调优思路是把“大表Join大表”降级为“大表Join小表”，然后使用上一讲中“大表Join小表”的调优方法来解决性能问题。

它的核心思想是，先把一个复杂任务拆解成多个简单任务，再合并多个简单任务的计算结果。
步骤:
1.对相对小表来说,将其通过过滤条件，拆分成N个不重复的子集。
2.union
大表 left join 小表子集1
union all
大表 left join 小表子集2

三、如何保证内表拆分的粒度足够细？
小表子集，一定要确保都可以放在内存广播里，即拆分的足够细。
即拆分的key一定要有可识别度，不能是性别这类的字段做拆分。

经常用时间做拆分。
因此，选择日期作为拆分列往往是个不错的选择，既能享受到Spark SQL分区剪裁（Partition Pruning）的性能收益，同时开发成本又很低。

四、如何避免外表的重复扫描？
上面的方案，我们会发现最大的问题是 大表被扫描N次。这是无法接受的。
可以利用DPP分区列裁剪的方式,对大表也进行逻辑划分，划分为分区字段。这样大表就不需要扫描全表N次了，只需要扫描对应的分区即可。
