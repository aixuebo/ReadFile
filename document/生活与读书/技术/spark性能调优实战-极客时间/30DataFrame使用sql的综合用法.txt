一、背景与总结


二、filter
val users = usersDf
.select("name", "age", "userId")
.filter($"age" < 30)
.filter($"gender".isin("M"))


三、join
a./*+ broadcast(t2) */  or /*+ mapjoin(t2) */
b.table1.join(table2.hint(“broadcast”), Seq(“key”), “inner”) //table2增加hint。
c.import org.apache.spark.sql.functions.broadcast //利用广播函数 broadcast
table1.join(broadcast(table2), Seq(“key”), “inner”)


val jointDF: DataFrame = salaries.join(employees, salaries("id") === employees("id"), "inner") //分别来自于不同表的id进行join

demo:
val result = txDF.select("price", "volume", "userId")
.join(users, Seq("userId"), "inner")
.groupBy(col("name"), col("age")).agg(sum(col("price") * col("volume")).alias("revenue"))


四、学习demo
1.基础使用
### 比如摇号3次的人有多少人。
select x_axis,count(*) y_axis
from
(
  select carNum,count(*) x_axis ###每一个摇号id，摇号次数
  from biao 
  group by carNum
) a

val result02_01 = applyDistinctDF
.groupBy(col("carNum"))
.agg(count(lit(1)).alias("x_axis"))
.groupBy(col("x_axis"))
.agg(count(lit(1)).alias("y_axis"))
.orderBy("x_axis")

2.join+withColumn
val result02_02 = applyDistinctDF
.join(luckyDogsDF.select("carNum"), Seq("carNum"), "inner")
.withColumn("ratio", round(col("molecule")/col("denominator"), 5)) ### 增加一列
.groupBy(col("carNum")).agg(count(lit(1)).alias("x_axis"))
.groupBy(col("x_axis")).agg(count(lit(1)).alias("y_axis"))
.orderBy("x_axis")

3.复杂case
val result05_01 = applyNumbersDF
.join(luckyDogsDF.filter(col("batchNum") >= "201601")
.select("carNum"), Seq("carNum"), "inner")
.groupBy(col("batchNum"),col("carNum"))
.agg(count(lit(1)).alias("multiplier"))
.groupBy("carNum")
.agg(max("multiplier").alias("multiplier"))
.groupBy("multiplier")
.agg(count(lit(1)).alias("cnt"))
.orderBy("multiplier")