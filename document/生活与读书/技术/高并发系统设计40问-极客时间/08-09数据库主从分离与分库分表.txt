一、背景与总结
数据库如何抵抗高并发和大流量的冲击的读写冲击。

1.主从分离 --- 实现上是读写分离，解决了查询吞吐量问题。同时 可以当备库，避免主库故障导致数据丢失。
每一台服务器的数据内容都是相同的。
相当于nosql的Replica副本。

2.分库分表 --- 解决写入数据量增加时，都放一个库里写数据，会造成数据量太大，影响查询相应问题。
工业上,所有数据库的表基本上只有一张，因为都是微服务的方式做工程，所以功能上的拆分已经在设计阶段解耦了。
此时说的分库分表，一定是某一个功能微服务拆分后，依然有很大的数据量，需要进一步拆分多个库，或者多个表存储。

不同于主从分离，他是数据分离，即每一台节点的数据是不同的。

相当于nosql的分片，Shard。

二、主从读写分离 --- 在读流量比较大的情况下，我们可以部署多个从库共同承担读流量。 同时 可以当备库，避免主库故障导致数据丢失。
通过同样数据分布在N台从节点上，使用负载均衡,将请求分发到不同读节点读取数据，解决查询吞吐量的瓶颈问题。

本质上他也不属于水平扩展，他只是X轴的扩展问题。

1.主从读写的两个技术关键点
a.一个是数据的拷贝，我们称为主从复制；
b.在主从分离的情况下，我们如何屏蔽主从分离带来的访问数据库方式的变化，让开发同学像是在使用单一数据库一样。

2.主从复制步骤
a.主库，数据写入成功 --> 创建binlog记录。
b.主库,有一个log dump线程来发送binlog给从库。
单独开启的线程，因此不影响binlog正常流程。
c.从库，开启一个线程，连接主库，发送请求到主库,获取binlog增量信息 ---> 接收主库返回的binlog信息 ---> 存储从库本地的relay log的日志文件中。
d.从库,创建一个线程，读取relay log日志内容 ---> 在从库做回放 --> 主从复制最终一致性。
单独一个线程，也是起到解耦，在相对空闲的时候，去做回放。

3.缺点 

第一，
因为异步操作，写入主库，从库读取到的数据可能存在延迟。
比如微博博主写了一个博客，推送给所有关注粉丝，粉丝可以看到信息内容。
此时推送的方式是kafka，将博客ID发送出去，粉丝获取到id后，读取id对应的数据内容。此时就会因为id还没有同步到从库，导致粉丝看不到结果。

解决方案:
1.数据冗余推送,及kafka的消息里,不仅仅有id,还有其他全部需要的信息。避免其他系统查询数据库。
2.使用缓存，将信息写入mysql后，还写入到缓存里，粉丝查看缓存即可。但此时要注意数据保持一致性的问题。（所以推荐使用方案1）。
在更新数据的场景下，先更新缓存可能会造成数据的不一致，比方说两个线程同时更新数据，线程A把缓存中的数据更新为1，
此时另一个线程B把缓存中的数据更新为2，然后线程B又更新数据库中的数据为2，
此时线程A更新数据库中的数据为1，这样数据库中的值（1）和缓存中的值（2）就不一致了。

第二，要有监控，把从库落后的时间作为一个重点的数据库指标做监控和报警，正常的时间是在毫秒级别，一旦落后的时间达到了秒级别就需要告警了。

3.在主从分离的情况下，我们如何屏蔽主从分离带来的访问数据库方式的变化，让开发同学像是在使用单一数据库一样。
使用中间件的方式，比如访问同一个数据源，该数据源配置好哪些库是写库，哪些库是读库。
程序还是只访问一个中间件连接，通过sql的解析，自己判断路由。

三、分库分表
1.数据量太大有什么影响。
a.解决写入数据量增加时，都放一个库里写数据，会造成数据量太大，影响查询相应问题。
b.数据量太大，影响了数据库的备份和恢复的时间。
c.数据隔离问题 -- 不同模块的数据，比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块都会受到影响。

2.如何对数据库做垂直拆分
a.垂直拆分，顾名思义就是对数据库竖着拆分，也就是将数据库的表拆分到多个不同的数据库中。
其实垂直拆分，是在拆分微服务。将不同服务的表，要拆分大盘不同的数据库里。这个是基本能力，不应该算到数据库扩展重点。
b.基于一种策略，将数据分发到不同的节点。
即不同于主从分离，他是数据分离，即每一台节点的数据是不同的。

c.举例
在微博系统中有和用户相关的表，有和内容相关的表，有和关系相关的表，这些表都存储在主库中。
在拆分后，我们期望用户相关的表分拆到用户库中，内容相关的表分拆到内容库中，关系相关的表分拆到关系库中。

3.如何对数据库做水平拆分 --- 拆分学习的重点
a.此时一定是某一个具体的微服务，数据依然很大，比如订单系统，那自然一个库存不下，需要多个库存储该数据。
b.拆分规则，按照某一个字段hash。比如常用ID字段
比如说我们想把用户表拆分成16个库，每个库是64张表，
那么可以先对用户ID做哈希，哈希的目的是将ID尽量打散，然后再对16取余，这样就得到了分库后的索引值；对64取余，就得到了分表后的索引值。
c.拆分规则，按照数仓理念，dt拆分，即按照发生的时间段来区分。因为数据库里有创建时间，很多场景用户只是看最近的文章而已。
缺点是，容易发生热点问题。


4.解决分库分表引入的问题
a.分库分表引入的一个最大的问题就是引入了分库分表键，也叫做分区键，也就是我们对数据库做分库分表所依据的字段。
无论是哈希拆分还是区间段的拆分，我们首先都需要选取一个数据库字段，这带来一个问题是：我们之后所有的查询都需要带上这个字段，
如果像上面说的要拆分成16个库和64张表，那么一次数据的查询如果没有带有分区键字段，则会变成16*64=1024次查询，查询的性能肯定是极差的。

解决方法
比如我们用ID做分区键，但查询的时候想用昵称查询。怎么办？
建立昵称和ID的映射表即可。该表如果存储在mysql里，则也可以进一步使用分库分表存储该数据。

b.多表的JOIN在单库时是可以通过一个SQL语句完成的，但是拆分到多个数据库之后就无法跨库执行SQL了。
系统侧每次查询的数据量不会很大，因此可以分别查询，然后程序内存join解决。

c.分库分表,在count计算总条数问题不可用。
解决方法，将计数的数据单独存储在一张表中或者记录在Redis里面。

5.分库分表后，作为某一个微服务的数据存储节点，可以继续 使用“主从分离”方式，扩展每一个读取节点的性能。
