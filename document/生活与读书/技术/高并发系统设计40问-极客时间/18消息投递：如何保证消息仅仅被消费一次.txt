一、背景与总结
1.要解决什么问题? -- 如何保证产生的消息一定会被消费到并且只被消费一次呢
因为系统已经通过消息队列，解耦了，所以已经不是原始的同步操作了，同步操作可以有事物控制，但异步操作，而且是解耦的异步操作(可能是若干个小时之后才操作)，
那么如何保证消息准确的发送给下游消息队列了(即消息队列没有丢失数据)，消息队列也不会被重复消费(即消息队列中不会重复插入数据)呢?

即:如何防止消息在投递的过程中丢失；如何防止消息在投递的过程中重复。

2.结论
a.其实防止肯定不丢失，其实是很难的，而且成本很大，会影响消息队列的额吞吐率，需要做重复发送到消息队列 && 消息队列内使用ack。
b.为了避免消息丢失我们需要付出两方面的代价：一方面是性能的损耗，一方面可能造成消息重复消费。
性能的损耗我们还可以接受，因为一般业务系统只有在写请求时才会有发送消息队列的操作，而一般系统的写请求的量级并不高。
c.既然重复数据写入是很难避免的，只需要保证消费的幂等性即可。这个相对是容易做到的。

3.幂等性
如果 一次提交，在此期间程序自动重复提交，或者不断刷新页面，算重复提交，需要幂等性进行处理。
如果用户在页面，本身就提交了N次，这不属于幂等性的范畴，他就是多次提交。

4.原则
幂等性是有性能损耗的，也会增加开发成本，因此方案设计看场景，你不能把所有的消息队列都配置成防止消息丢失的方式，也不能要求所有的业务处理逻辑都要支持幂等性，这样会给开发和运维带来额外的负担。

二、消息为什么会丢失 --- 如果要保证消息只被消费一次，首先就要保证消息不会丢失。
1.丢失的主要存在三个场景：
消息从生产者写入到消息队列的过程；
消息在消息队列中的存储场景；
消息被消费者消费的过程。

1.1 消息从生产者写入到消息队列的过程；
内网抖动，毕竟生产者是业务服务器、消息队列是单独的服务器。两者传输数据需要依赖网络。
解决方案是消息重传。也就是当你发现发送超时后就将消息重新发一次，一般重复2~3次就可以了。
这种方案可能会造成消息的重复：比方说消息生产时由于消息队列处理慢或者网络的抖动，导致虽然最终写入消息队列成功但在生产端却超时了，生产者重传这条消息就会形成重复的消息。

1.2.在消息队列中丢失消息
a.消息队列的实现上，可能会丢失数据。
比如kafka,虽然是存储在磁盘上,但先写入内存，然后再刷新到磁盘。如果发生机器掉电或者机器异常重启，内存中还没有来得及刷盘的消息就会丢失了。

解决方案:如果对数据丢失容忍度高，可忽略，毕竟断点场景不多。
如果对数据丢失容忍度低，比如金融业务，可以考虑以集群方式部署Kafka服务，通过部署多个副本备份数据保证消息尽量不丢失。

b.实现原理 --- ack其实实现成本还是很大的。
Kafka集群中有一个Leader负责消息的写入和消费，可以有多个Follower负责数据的备份。
Follower中有一个特殊的集合叫做ISR（in-sync replicas），当Leader故障时，新选举出来的Leader会从ISR中选择，
默认Leader的数据会异步地复制给Follower，这样在Leader发生掉电或者宕机时，Kafka会从Follower中消费消息，减少消息丢失的可能。

由于默认消息是异步地从Leader复制到Follower的，所以一旦Leader宕机，那些还没有来得及复制到Follower的消息还是会丢失。
为了解决这个问题，Kafka为生产者提供一个选项叫做“acks”，当这个选项被设置为“all”时，
生产者发送的每一条消息除了发给Leader外还会发给所有的ISR，并且必须得到Leader和所有ISR的确认后才被认为发送成功。
这样，只有Leader和所有的ISR都挂了消息才会丢失。

当设置“acks=all”时，对于消息生产的性能来说也是有比较大的影响的，所以你在实际应用中需要仔细地权衡考量。我给你的建议是：
第一,如果你需要确保消息一条都不能丢失，那么建议不要开启消息队列的同步刷盘，而是用集群的方式来解决，可以配置当所有ISR Follower都接收到消息才返回成功。
第二，如果对消息的丢失有一定的容忍度，那么建议不部署集群，即使以集群方式部署，也建议配置只发送给一个Follower就可以返回成功了。
第三，我们的业务系统一般对于消息的丢失有一定的容忍度。

1.3.在消费的过程中存在消息丢失的可能
消费的过程分为三步：接收消息、处理消息、更新消费进度。

这里面接收消息和处理消息的过程都可能会发生异常或者失败，比如消息接收时网络发生抖动，导致消息并没有被正确地接收到；
处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度，这条失败的消息就永远不会被处理了，也可以认为是丢失了。

所以，在这里你需要注意的是，一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题，
比方说某一条消息在处理之后消费者恰好宕机了，那么因为没有更新消费进度，所以当这个消费者重启之后还会重复地消费这条消息。

三、如何保证消息只被消费一次
1.为了避免消息丢失我们需要付出两方面的代价：一方面是性能的损耗，一方面可能造成消息重复消费。
性能的损耗我们还可以接受，因为一般业务系统只有在写请求时才会有发送消息队列的操作，而一般系统的写请求的量级并不高。
但重复消费的影响是非常大的，比如重复给订单付款。因此我们要解决的问题是在大环境肯定有重复数据产生的时候，如何做到消费者的幂等性。

2.生产者的幂等性
3.2.1 目的是减少消费者压力，即消息队列先将重复的生产者过滤掉。(这部分可能也不重要，即在消费者压力不大的情况下,这部可以不做，都由消费者兜底)
3.2.2解决方案
在Kafka0.11版本和Pulsar中都支持“producer idempotency”的特性，翻译过来就是生产过程的幂等性。
原理:
a.生产者有唯一ID，每一个消息也有唯一ID。
b.生产者客户端上传信息<生产者ID，消息ID，key，value>给服务端。
c.消息队列服务端维护<生产者ID，最后一条消息ID>映射。
d.服务端接受生产者信息后，先校验消息队列服务端会比对消息ID是否与存储的最后一条ID一致，如果一致就认为是重复的消息，服务端会自动丢弃。

3.消费者幂等性
3.1 原理流程
a.业务系统提交前，去申请业务唯一ID -- tokenId。同时系统服务端会存储tokenId到数据库。
b.业务系统提交数据，同时将tokenId也一起提交。<生产者ID，消息ID，key，value,tokenID>
c.消费者消费数据时，查询tokenId是否存在，存在则说明要去消费。不存在则说明已经重复消费，该消费信息可以丢弃。
b.消费者消费数据，业务处理+删除tokenId。

3.2 存在的问题
业务处理+删除tokenId要在事务内触发，即要么同时成功，要么同时失败。

方案对比
a.如果业务逻辑数据库 与 token数据库是同一个数据库，并且在同一个库里，即每一个token要与业务库在一起。这样天然是有事务可以支持的。
b.a场景有时候不行，因为token很多时候是集中式的，由token中心发放与维护，此时天然就不支持事务，而分布式事务又很重。但似乎只能是用分布式事务处理。
c.允许一定量的重复消费，即在高并发下，在业务逻辑与删除token之间，会触发多次重复提交，造成的概率较低，是否允许，如果允许就不需要事务，开发复杂度会减轻很多压力。
d.单线程处理业务逻辑，因此就不会出现 业务逻辑 与 token删除之间有并发问题，也间接的解决了幂等性问题。
e.如何保证事务，又实现简单的方案
可以将 业务逻辑 + token删除拆分成2部分，即先 “验证token是否存在并删除 token”，再“业务逻辑”执行。
而验证并删除 token，此时在token数据中心，是可以事务操作的，或者 假设token存储在redis里，则使用redis的delete，返回是否删除成功，也是可以实现事务级别的语义。即redis要用删除操作来判断token，删除成功代表token校验通过。
第一步成功后，再执行第二步，如果第二步失败，可以直接认为操作失败, 但并不会破坏接口的幂等性，大不了用户再次提交一次，用户牺牲了体验，但操作是安全的。


四、扩展知识
4.1 系统测为什么要解决接口幂等性问题
系统接到多次消息，由于每次消息间隔会有几秒，所以延迟了许久的消息应该及早拒绝, 返回失败，不仅为了避免重复调用，也保证了系统不过载而触发系统雪崩。要及早释放资源。
4.2 非幂等性带来的问题
用户花200元买"赵云-子龙"皮肤，结果没反应，用户测试，点了”闭月之颜-貂蝉”皮肤，结果提示购买成功。用户哭了。
解决方案:保证同一个用户的请求路由到固定的服务器处理，并且由TCP协议确保顺序。

