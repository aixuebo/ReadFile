一、向量归一化
不同的公式应用不同的场景会效果更好
1.比如数学考试,全班有50个同学
那么每次成绩出来都是50个元素组成的向量
如果考试10次,那么就是10个向量
但是考试的难度不同,因此对于同一个人的影响会较大,因此要做归一化处理,消除因为难度的影响造成的现象

a.针对每一次考试成绩,我们可以知道这组向量成绩对应的均值和方差
我们让每一个学生的成绩做如下处理
(成绩-均值)/方差,这样组成50个新的向量,就是归一化后的向量。

那么10次考试,每次多这么处理,就出现了新的10个向量,我们就可以通过新的向量,排除了考试难度引起的变化。

这种方式叫做最终均值为0,方差为1的影响,即每一个用户的

2.用(每一个学习成绩-最小的成绩)/(最大的成绩-最小的成绩)
3.向量的每一个元素/该向量的模.表示消除该向量大小的影响,仅仅考虑该向量的方向


如何计算向量的长度:
向量所有元素的平方和,即两个相同自身的向量进行times运算,即每一个元素*该元素,这就是每一个元素的平方和
该平方和的开方,就是向量的长度


二、如果计算一个向量属于某一个向量的概率
  /**
   * 返回该元素属于该模型的概率
   * 因为该类DistanceMeasureCluster本身就表示一个分类,因此该方法表示参数向量 属于 本类这个分类的可能性
   * 既然是可能性,那么就是一个概率,属于0-1之间的概率
   *
   * 那么怎么转换成概率呢,
   * 已知是 两个向量之间的距离越大,说明越不是一个分类
   *
   * 如果我们用1/距离,因此距离越大,说明值越小,这样就说明概率越小,但是分母距离又不能为0,因此分母用1+距离,刨除0带来的隐患。
   * 而且由于距离还可能是0-1之间分数,因此1/0.5 就变成大于100%的概率了,也不对,因此分母用1+距离也可以保证一定分母是大于1的整数,得到的概率一定是0-1之间,这样就非常完美了
   *
   * 至于分母用1+距离,那么我用2+距离可以吗？答案是完全可以的
   */
  @Override
  public double pdf(VectorWritable vw) {
    return 1 / (1 + measure.distance(vw.get(), getCenter()));
  }