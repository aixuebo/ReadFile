实时数仓
Demo  窗口状态变化组合多，用户数过滤重复，并且需要补充维度属性
1.维度表怎么实现的。
实时处理中，如何关联大维度表，比如商品维度表(sku历史存量很大,上亿条，同时系统测还在不断新增、修改sku数据)
比如订单流有skuid,我想补充一些sku属性输出到下游。
问题是skuid对应的维度属性不在另外一个流了，此时只能PRC通过skuid请求系统接口来解决吗？那QPS会不会太高了。实践场景下，有什么好的处理方式么？

答复:
流流增量关联 + 维表关联实现。
1.增量sku维度信息，接入binlog流，这样新增、update数据可以做合并，此时流流合并可能时间窗口不一致，比如sku维度表流可能存储1天的数据。 因为如果时间窗口相同的话，可能命中率低，因为sku创建后的一小段时间内(比如10分钟),可能不会有订单，但当天可能会有订单。所以订单量最好关联一天的增量流，因此要看是否可以不同窗口流做join。
2.存量维度表同步到tair。T+1同步。
维度表的新增、更新操作，也要刷新同步到维表。此时流流关联不到的数据，可以通过查询tair的方式获取数据，缺点就是吞吐量低。


2.周期长的指标，如何计算。以及加distinct难度提升，如何计算与存储。
比如统计最近一个月同一个ip的访问用户数。


就用的 mapstate，放在 rocksdb 里，rocksdb 的 key 是去重 ID。
千万的话，你有 1000 并行度，那每个并行度才 1w.
1w * 8byte = 80KB
1000w * 8byte = 80MB  你主要看磁盘的 io 会不会被打满。

设备号字符串转成long，有啥好方法么，除了利用物理数据库，比如插入mysql，转换成一个自增主键外，有其他好方法么，可以不用数据库，算法转换那种
flink 就 keyBy 路由规则就是 murmurHash 算法，错误率千万分之一。


3.窗口函数一个周期就一个资源被一直占用吗
任务要评估最大任务需求，开启任务需求需要的资源。
如果资源不足时，需要重新启动任务，此时会出现短暂的断流。



flink 
1.state的key group 与 arrage的价值
https://blog.csdn.net/nazeniwaresakini/article/details/104220138
为什么要这么区分,是因为flink管理内部中间状态,避免当并行度扩容后,状态性能差,设置一个极大的group ，在group为单位基础上,对并行度重新划分。
2.获取存储方式
val lastTempState: ValueState[Double] =getRuntimeContext.getState(new ValueStateDescriptor[Double]("lastTemp", classOf[Double]))
一个节点会初始化一个内存状态，key就是节点的key类型,value设置好类型,大内存就可以存储数据了。
忽略下游如何实现的，是系统解决的问题。