Flink的状态实现方案与应用
——————————————
主题1 如何实现分布式状态存储
一、基于 Redis 的状态集群
1.当采用 Redis 集群实现分布式状态存储和管理时，流计算集群和 Redis 集群节点是分离开的。流计算集群中的每个节点都可以任意访问 Redis 集群中的任何一个节点。
2.优缺点
优点:可以任意增加流计算节点、redis节点，增加时，对彼此不会有影响。
缺点:以“过去一天同一用户的总交易金额”为例。如果将“1 天”分成 24 个“1 小时”的子窗口。这样，在查询计算时将有 24 次的 Redis GET 操作。
假设6 台 Redis,因此极端情况会6台节点去执行IO请求。并且总请求次数是24次。
3.解决策略
a.局部性策略
去6台节点查询,是因为默认情况下，Redis Cluster 将数据按照 key 做 hash 后分散各个槽（slot）里，而槽又分布在各个 Redis 节点上。
最好的方式设置好key,一次查询的24条数据,都在一个slot里。
Redis为我们提供了贴心的标签（tag）功能，允许只使用 key 中的部分字段来计算 hash 值。
如果 hash_tag 指定为“{}”，那么当 key 中含有“{}”的时候，就不使用整个 key 来计算 hash 值，而只对“{}”包括的部分字段计算 hash 值。
比如 $event_type.{$userid}.$window_unit.$window_index
b.批次请求处理
首先,我们可以充分发挥 Redis 的 pipeline 功能。通过 Redis 的 pipeline 功能，可以一次性发送多条指令。当执行完后，这些指令的结果一次性返回。
如果这些数据不在同一个 Redis 节点上，我们就不能够使用 pipeline 的功能了。
经过上述的优化设计后，原本需要 24 次 IO 操作的特征计算，最优情况下降低为只需要一次 IO 操作。！

其次,批次请求处理是指将多个请求收集起来后，一次性成批处理的过程。批次请求处理可以有效提高 IO 资源的使用效率，并降低消息的平均处理时延。

二、基于分布式文件系统的状态集群
流计算节点上有一个状态存储能力，比如rackdb。
流计算节点针对状态的操作完全在本地进行，不涉及任何远程操作。
但如果只是这样，那当需要扩展或收缩集群的节点数时，怎么保证能够读取到原来的状态信息呢？
因此，在每个节点上，需要有专门的线程定期或在必要的时候（比如任务关闭前），对状态进行 checkpoint。
所谓 checkpoint，是指将本地状态后端里的数据做快照（snapshot）之后，保存到分布式文件系统里的过程。
当集群在节点数变化后再重启时，各个节点首先从分布式文件系统中读取其所负责数据分片所在的快照，再将快照恢复到状态后端里，
这样各个节点就获得重启前的状态数据了，之后的计算又可以完全在本地进行。

——————————————
主题2 状态的应用
一、状态人为的分类
1.流数据状态
处理事件窗口、时间乱序、多流关联等问题，通常需要对部分流数据进行临时缓存，并在计算完成时再将这些临时缓存清理掉。
因此原始数据的状态，应该由框架内部搞定。因此称之为流数据状态。
2.流信息状态
数据的聚合值等业务信息，比如时间维度的聚合值、关联图谱的一度关联节点数、CEP 的有限状态机等。
这些信息会存储在rackdb或者redis中,目的是后续计算时，会继续使用。
同时这些信息会不断的被查询、更新。

二、为什么要区分“流数据状态”和“流信息状态”。
比如计算“用户过去 7 天交易总金额”。每 1 秒钟计算一次 7 天窗口内的总交易金额。
source.keyBy(0)
.timeWindow(Time.days(7), Time.seconds(1)) // 滑动窗口，每1秒钟计算一次7天窗口内的交易金额
.sum(1);

1.存在的问题
a.每 1 秒钟才能输出结果，业务更需要的是每一个事件都要计算一次，而不是时间窗口1秒计算一次。
b.窗口7天,步长1秒,差距太大,这意味着对于同一份数据，在窗口滑动过程中，会被反复计算“7(天) ÷ 1(秒) ≈ 60万”次！
虽然步长可以调大,就会缩短60万次，但也是体量也很大，浪费存储，同时实时性差了。

2.是什么原因造成了以上这些不妥之处呢？
我们混淆了“数据窗口”和“业务窗口”。
开源流计算框架中，它们定义的“窗口”函数，其实是针对“流数据”的“分块”管理。本质上是对流数据的“分而治之”管理，所以我将这种窗口，称之为“数据窗口”。
而“用户过去 7 天交易总金额”的计算中，这里的“7 天”是属于业务意义上的时间窗口，所以我将这种窗口，称之为“业务窗口”。
我要实现“7 天”的“业务窗口”，为啥一定要用“7 天”的“数据窗口”来对流数据进行分块呢？

三、流数据状态
1.事件窗口
这些以“窗口”为单元来处理事件的方式，我们需要用一个缓冲区（buffer）临时存储过去一段时间接收到的事件。
只有等到触发窗口计算的条件满足时，才开始处理窗口内的事件。最后当窗口里的数据被处理完时，还需要将以后无须再使用的数据清理掉。
这种保存在缓冲区中的部分流数据，就是一种“流数据状态”。

2.时间乱序
怎样处理这种事件在时间上乱序的问题呢？通常的做法就是将收到的事件先保存起来，等过一段时间后乱序的事件到达了，再将保存的事件按时间排序，这样就恢复了事件的时间顺序。
等多久的解决方案是watermark。
在流计算数据中，按照一定的规律（比如以特定周期）插入“水印”，水印时间戳 = 当前时间戳 - N周期。

3.流的关联 join、union
join 操作时，需要先将参与 join 的各个流在一段时间窗口内的全部数据都缓存起来.
然后，以这些窗口内的数据为基础，做类似于关系型数据库中表与表之间的 join 计算。最后计算完成时，再将结果以流的方式输出。

4.除了以上三种主要用途外，流计算系统在实现其他一些功能时，也需要缓存部分的流数据，比如排序（sorting）、分组（group by）等。因此，这些功能也都使用到了“流数据状态”。
排序和分组，都会在节点预先缓存一部分数据。但基本上都是框架内部支持了，对外解耦，用户不需要关注这个。

四、流信息状态
主要的功能，是记录在流计算过程中分析出的业务信息。
流信息状态的存储，通常是依赖于数据库完成的。这有三方面的原因。
一是，“流信息状态”通常需要保存较长时间，数据量也不小，还需要频繁查询和更新，将它存放在数据库中，能方便地长期保存和增删查改。
二是，“流信息状态”存在“数据变冷”和“过期淘汰”的问题，使用数据库的“热数据缓存”和“TTL 机制”，能方便有效地解决这两个问题。
三是，“流信息状态”通常数据量会很大，单个存储节点往往是不够用的，选择合适的数据库能够方便地扩展为集群。

五、应用
1.流数据状态: "每1分钟统计一次过去1小时总交易金额"统计就是一个滑动窗口内的数据，因此直接在窗口内保存数据即可。
2.流信息状态:“每来一个事件就统计一次该事件对应用户过去7天总交易金额”,需要用到Keyed State来记录每个用户各天的交易金额
3.需求场景分类:
a.每一个独立窗口内可以统计的数据，窗口之间是完全解耦的，比如 就统计过去一小时的交易金额，此时窗口内解耦的。
b.窗口不是独立的,窗口之间的结果是有关系的。比如每一个窗口只是统计一部分数据，业务要的是一个累计汇总值，比如最近7天的总交易额。