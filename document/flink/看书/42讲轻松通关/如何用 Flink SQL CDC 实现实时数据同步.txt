Flink应用 -- 如何用 Flink SQL CDC 实现实时数据同步
一、背景
mysql数据，可能同步到hive、ES、redis中。使用场景是不同的。
二、方案
1.方案1:业务系统请求 --- 业务系统分别开启事务写入到N个存储中。
缺点:
代码严重耦合，每次需要修改业务代码,都可能影响到向N个库写数据的逻辑，产生bug。
在业务系统中需要多次将数据写入不同数据库，严重影响业务代码性能；
业务逻辑与同步代码(非业务逻辑)耦合在一起。
增量同步前，需要先由人工（至少你要写脚本和执行脚本吧）做一次全量同步。
2.方案2
业务系统请求 --- 业务系统存储到mysql，同时存储到kafka --- flink读kafka数据同步到不同的数据库中。
缺点:
业务库要耦合kafka，虽然只写了一个kafka数据，但还是有耦合，同时哪些表要同步都需要加这段同步kakfa代码，没有切面做这个。
增量同步前，同样需要先由人工做一次全量同步。
3.方案3
业务系统请求 --- 业务系统存储到mysql --- binlog写入kafka--- flink读kafka数据同步到不同的数据库中。
方案已经接近理想了，此时都解耦了，缺少的是flink这块框架能力，支持可配置的方式写入到不同的数据存储中。
同时缺点是引入了kafka，能否不引入kafka，而是flink直接实现binlog同步的能力呢？即flink中直接读取binlog数据。
4.Flink CDC（Change Data Capture，变化数据捕获）方案
我们通过 Flink CDC 技术，先将主数据库的全量数据同步到另外的数据库中，然后再跟随主数据库的 binlog 日志，将所有增量的数据也实时同步到从数据库中。
由于 Flink CDC 将全量同步和增量同步的操作封装到了一起，并且因为 Flink 还支持 SQL 语句，所以最终我们只需要写几行简单的 SQL，就能轻松解决将同一份数据写入多种不同数据库的问题。

三、实现原理
我们以使用 Flink CDC 从 MySQL 中同步数据的情景，来讲解下 Flink CDC 的工作原理。
一般来说，Flink CDC 同步数据需要两个步骤。
第一步是将源数据库的数据全量同步到目标数据库；
第二步是跟随源数据库的 binlog 日志，将源数据库的所有变动，以增量数据的方式同步到目标数据库。

我们先来看将源数据库的数据全量同步到目标数据库的过程。Flink CDC 将这个过程称之为“快照”（sanpshot），具体步骤是这样的。

1.Flink CDC 会获取一个全局读锁（global read lock），从而阻塞其他客户端往数据库写入数据。不用担心这个锁定时间会很长，因为它马上就会在第 5 步中被释放掉。
目的获取binlog位置。
2.启动一个可重复读语义（repeatable read semantics）的事务
3.读取当前 binlog 的位置。
4.读取 Flink CDC 配置指定的数据库和表定义(schema)。
5.释放步骤 1 中的全局读锁。这个时候其他的客户端就可以继续往数据库中写入数据了。
从步骤 1 到步骤 5，Flink CDC 并没有做非常耗时的任务，所以全局锁定的时间很短，这样对业务运行的影响可以尽量降至最小。
6.将步骤 4 读取的数据库和表定义，作用到目标数据库上。
对数据库里的表进行全表扫描，将读取出的每条记录，都发送到目标数据库。
完成全表扫描后，提交（commit）步骤 2 时启动的可重复读语义事务。
将步骤 3 读取的 binlog 位置记录下来，表明本次数据全量同步过程（也就是“快照”）成功完成。

数据全量同步的过程还是比较复杂的，但好在 Flink CDC 的flink-connector-mysql-cdc 连接器插件已经为我们实现了这个过程，所以我们直接使用它就好了。

完成数据全量同步后，后面的增量同步过程就相对简单了，直接跟随源数据库的 binlog 日志，然后将每次的数据变更同步到目标数据库即可。
增量同步过程中，Flink 自己会周期性地执行 checkpoint 操作，从而记录下当时增量同步到的 binlog 位置。
这样，如果 Flink CDC 作业（job）因为发生故障而重启的话，也能够从最近一次 checkpoint 处，恢复出故障发生前的状态，从而继续执行之前的过程。

四、具体实现
1.基于 DataStream 的方式
public class FlinkCdcDemo {
    public static void main(String[] args) throws Exception {
        // 源数据库，下面是以 MySQL 作为源数据库的配置
        SourceFunction<String> sourceFunction = MySQLSource.<String>builder()
                .hostname("127.0.0.1")
                .port(3306)
                .databaseList("db001")
                .username("root")       // 测试用，生产不要用root账号！
                .password("123456")     // 测试用，生产不要用这种简单密码！
                .deserializer(new StringDebeziumDeserializationSchema())
                .build();
        // 目标数据库，下面是以 Elasticsearch 作为目标数据库的配置
        List<HttpHost> httpHosts = new ArrayList<>();
        httpHosts.add(new HttpHost("127.0.0.1", 9200, "http"));
        ElasticsearchSink.Builder<String> esSinkBuilder = new ElasticsearchSink.Builder<>(
                httpHosts,
                new ElasticsearchSinkFunction<String>() {
                    private IndexRequest createIndexRequest(String element) {
                        Map<String, String> json = new HashMap<>();
                        // 这里直接将数据 element 表示为字符串
                        json.put("data", element);
                        return Requests.indexRequest()
                                .index("table001")
                                .source(json);
                    }
                    @Override
                    public void process(String element, RuntimeContext ctx, RequestIndexer indexer) {
                        // 这里就是将数据同步到目标数据库 Elasticsearch
                        indexer.add(createIndexRequest(element));
                    }
                }
        );
        // 实验时配置逐条插入，生产为了提升性能的话，可以改为批量插入
        esSinkBuilder.setBulkFlushMaxActions(1);
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env
                .addSource(sourceFunction)  // 设置源数据库
                .addSink(esSinkBuilder.build())  // 设置目标数据库
                .setParallelism(1); // 设置并行度为1，以保持消息顺序
        env.execute("FlinkCdcDemo");
    }
}

2.基于 Table & SQL 方式
-- 在 Flink SQL Client 里执行以下 SQL。
-- 创建源数据库
CREATE TABLE sourceTable ( ### 待同步的mysl的表结构
  id INT,
  name STRING,
  counts INT,
  description STRING
) WITH ( ### mysql的连接方式
 'connector' = 'mysql-cdc',
 'hostname' = '192.168.1.7',
 'port' = '3306',
 'username' = 'root',
 'password' = '123456',
 'database-name' = 'db001',
 'table-name' = 'table001'
);
-- 创建目标数据库
CREATE TABLE sinkTable (
  id INT,
  name STRING,
  counts INT
) WITH (
  'connector' = 'elasticsearch-7',
  'hosts' = 'http://192.168.1.7:9200',
  'index' = 'table001'
);
-- 启动 Flink SQL CDC 作业
insert into sinkTable select id, name, counts from sourceTable;

因此3个sql就可以配置完成同步任务工作。