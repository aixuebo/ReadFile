一、基本原理
1.segment文件
每一个topic-partition是一个文件,在一个broker上存在该文件,名字是该partition的最开始的偏移量,文件里面存储的是key=value以及偏移量信息
2.segment包含index和log文件,index方便定位到一个偏移量
3.每一个partition的segment文件的内容是顺序存储到broker上的
4.生产者向kafka写入数据,可以自定义partition方法,让不同的key存放到不同的partition上,默认是使用的hash方式分发的
5.partition的数据和消费者的数量,如果partition有5个,则kafka消费者最多有5个是可以用的,即一个消费者可以消费多个partition,但是最多也就5个消费者就消费完成了
如果是6个消费者,则有一个消费者是没有用的


二、如何保证kafka有且只消费一次,即有时候会重复消费,有时候会丢数据
问题产生的可能情况:
1.当多了一个消费者或者少了一个消费者的时候,即rebanlance的时候,因为offset读取可能存在问题,导致会发生重复消费或者丢失消费
2.消费的过程中发生的异常,比如已经客户端消费了,offset更改了,但是业务逻辑出现的问题,导致没有真的消费成功
解决方法:手动提交offset
3.项目停止的时候,kafka消费线程还在跑,没有写hook,因此程序已经消费了,但是kafka没有提交,因此也会导致重复消费
解决方法:编写hook,当kafka的消费者跑完后,再停止程序

