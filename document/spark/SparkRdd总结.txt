

  private[scheduler] def handleJobSubmitted(jobId: Int,

  ------
    def hadoopFile[K, V](
      path: String,
      inputFormatClass: Class[_ <: InputFormat[K, V]],
      keyClass: Class[K],
      valueClass: Class[V],
      minPartitions: Int = defaultMinPartitions): RDD[(K, V)] = withScope {
    assertNotStopped()
    // A Hadoop configuration can be about 10 KB, which is pretty big, so broadcast it.
    //使用java的方式对hadoop的Configuration信息进行序列化与发序列化
    val confBroadcast = broadcast(new SerializableConfiguration(hadoopConfiguration))
    //定义一个函数,参数是JobConf,无返回值,该函数将path写入hadoop的输入源中
    val setInputPathsFunc = (jobConf: JobConf) => FileInputFormat.setInputPaths(jobConf, path)
    new HadoopRDD(
      this,
      confBroadcast,
      Some(setInputPathsFunc),
      inputFormatClass,
      keyClass,
      valueClass,
      minPartitions).setName(path)
  }

def textFile方法解析
1.即给定一个path,使用TextInputFormat类读取该hadoop路径,解析key-value类型为long和Text,使用多少个partition读取  返回HadoopRDD,即RDD[(KEY,VALUE)]
2.调用RDD[(KEY,VALUE)].map(pair => pair._2.toString) 返回MapPartitionsRDD[String] RDD[String] 即对每一个RDD的Partition中key-value的迭代器 循环 只要value的值


细节
1.返回HadoopRDD,即RDD[(KEY,VALUE)]的过程
a.使用InputFormat的getSplits方法切分path路径,返回Split数组
  每一个split数组转换成HadoopPartition对象,即返回HadoopPartition数组,HadoopPartition由RDDID 第几个split 以及split对象组成

------------------------------------------------------------------------------------

RDD的基本功能
一、Transformations
1.map
def map[U: ClassTag](f: T => U): RDD[U]
方法对该RDD的某一个partition处理,每一个T通过一个函数转换成U,f: T => U,最终是MapPartitionsRDD[U]类型的RDD
2.flatMap
def flatMap[U: ClassTag](f: T => TraversableOnce[U]): RDD[U]
方法对该RDD的某一个partition处理,每一个T通过一个函数f: T => TraversableOnce[U] 该函数可以将T转换成一个集合
3.filter
def filter(f: T => Boolean): RDD[T]
方法对该RDD的某一个partition处理,每一个T通过一个函数f: T => Boolean,只有返回true的才允许通过,组成新的RDD[T]
4.distinct 返回一个新的RDD,新的RDD就是把老的RDD中重复的元素去掉了
def distinct(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T]
a.通过map转换成MapPartitionsRDD[(key,null)]元组RDD,该RDD通过隐式转换成PairRDDFunctions对象,该对象持有该RDD
一定需要shuffle,按照key相同的分配到同一个组里面,然后对相同的key对应的value在执行合并函数
5.mapPartitions
a.
def mapPartitions[U: ClassTag](f: Iterator[T] => Iterator[U],
      preservesPartitioning: Boolean = false): RDD[U] {
相当于Map操作,他是一个变种,map输入函数是应用于RDD中每个元素，而mapPartitions的输入函数是应用于每个分区，也就是把每个分区中的内容作为整体来处理的。

b.def mapPartitionsWithIndex[U: ClassTag](
        f: (Int, Iterator[T]) => Iterator[U], //f参数int表示第几个partition,iter表示该partition的数据源的迭代器,返回新的迭代器
        preservesPartitioning: Boolean = false): RDD[U]
也是mapPartitions的升级版本,就是参数不仅仅是需要partition的内容的迭代器,还需要知道这个任务是第几个任务,即map的ID

6.  def repartition(numPartitions: Int)(implicit ord: Ordering[T] = null): RDD[T] 调用 coalesce(numPartitions, shuffle = true)
  就是简单的将父RDD的多个partition合并成一个partition的过程,虽然有网络获取数据的内容,但是不涉及真正意义上的shuffle操作,即不涉及key相同的都要在一个节点上存在步骤
7.def coalesce(numPartitions: Int, shuffle: Boolean = false)(implicit ord: Ordering[T] = null) : RDD[T]
参数shuffle = true表示要进行一次shuffe操作去重新设置partition
   如果shuffle = false 表示不会进行shuffle,只是一对多的,将多个父RDD的partition合并成一个,虽然有网络IO,但是不涉及key相同的都要在一个节点上存在步骤
参数numPartitions 表示最终需要的partition数量
该函数是将父RDD的partition数量重新调整,一般用于RDD的partition较多又较小的时候,重新规划

注意:
shuffle true的时候,让每一个原始的RDD的每一个partition产生一个新的key,key的内容就是自增长的ID,,让shuffle根据id作为key的时候更均匀的分布在多个节点上,依然不用保证key相同的都在同一个节点上

8.def union(other: RDD[T]): RDD[T] 或者 def ++(other: RDD[T]): RDD[T]
将两个RDD进行合并，不去重
9.def intersection(other: RDD[T]): RDD[T]
函数返回两个RDD的交集，并且去重。
将两个集合的key转换成<key,null>这样K-V结构的就可以调用的PairRDDFunctions里面<K,V>结构的cogroup逻辑,这样得到的同一个key的两个结果集都存在的,则就是需要的交集
10.def cartesian[U: ClassTag](other: RDD[U]): RDD[(T, U)]
对两个RDD进行笛卡尔计算,返回RDD[(T, U)],这个函数对内存消耗较大,使用时候需要谨慎
即两个RDD每一条记录都相互笛卡尔运算
11.def groupBy[K](f: T => K)(implicit kt: ClassTag[K]): RDD[(K, Iterable[T])]
将RDD中的T元素通过函数转换成另外对象,然后组成<K,T>的元组,从而使用PairRDDFunctions的groupBy,将数据按照K进行分组
12.def zip[U: ClassTag](other: RDD[U]): RDD[(T, U)]
将两个RDD每一个元素拿出来,作为元组
比如
scala> var rdd1 = sc.makeRDD(1 to 5,2)
rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[1] at makeRDD at :21

scala> var rdd2 = sc.makeRDD(Seq("A","B","C","D","E"),2)
rdd2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[2] at makeRDD at :21

scala> rdd1.zip(rdd2).collect
res0: Array[(Int, String)] = Array((1,A), (2,B), (3,C), (4,D), (5,E))

13.def keyBy[K](f: T => K): RDD[(K, T)]
将元素T通过函数转换成K,组装成K,T的元组

14.def sortBy[K](
         f: (T) => K,
         ascending: Boolean = true,
         numPartitions: Int = this.partitions.length)
         (implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T]
按照函数f对元素进行排序,返回的RDD还是原来的RDD,只是进行了一次按照f函数来排序的过程
该函数会产生一个shuffle操作
将RDD[T]转换成RDD[K,T],然后因为K是有排序功能的,因此shuffle按照K排序,排序后获取所有排序后的Vlaue集合









Actions
1.reduce(f: (T, T) => T): T
调用集合的reduceLeft方法,这个是scala的方法,意思是循环迭代集合,每两个相邻的对象执行一下f方法,结果在与下一个对象运算
2.def subtract(other: RDD[T]): RDD[T]
返回在RDD中出现，并且不在otherRDD中出现的元素，不去重
将x变成(x,null) 这样K-V结构的就可以调用的PairRDDFunctions里面<K,V>结构的subtract逻辑





------------------------------------------------------------------------------------
PairRDDFunctions(持有K-V元组形式的RDD作为私有属性,一切RDD操作都是操作该K-V类型的RDD)
1.combineByKey[C](createCombiner: V => C,//可以value转换成C的函数
      mergeValue: (C, V) => C,//对每一个C与V交互生成C的函数
      mergeCombiners: (C, C) => C,//将多个C进行合并的函数
该方法一定发生shuffle了
对key不存在的,走第一个参数,让key转换成c
对key存在的,则找到对应的C,然后与此时的key对应的value进行运算,走第二个参数
第三个参数相当于reduce操作
2.def aggregateByKey[U: ClassTag](zeroValue: U, partitioner: Partitioner)(seqOp: (U, V) => U,
      combOp: (U, U) => U): RDD[(K, U)] = self.withScope {
该方法与combineByKey方法类似,只是第一次出现key的时候,不需要进行key对应的value转换成C,而是用初始化的值zeroValue与此时的value进行合并,即调用combineByKey的第二个参数
3.def reduceByKey(partitioner: Partitioner, func: (V, V) => V): RDD[(K, V)]
按照key进行group by,key相同的进行合并,最终调用的还是combineByKey方法
4.def foldByKey(
      zeroValue: V,
      partitioner: Partitioner)(func: (V, V) => V): RDD[(K, V)]
与reduceByKey一样,都是对V进行处理,返回值还是V,只是区别在于.每一个key的第一个value,要与初始值一起参与F运算,而reduceByKey第一次出现的V就直接返回V
5.def reduceByKeyLocally(func: (V, V) => V): Map[K, V]
在一个partition节点上,将一个partition的迭代器作为参数,在内存中计算,对key进行分组,相同key的value进行func函数运算,因此有内存问题。
如果key很多的时候,会真用很大内存空间。
6.mapValues
def mapValues[U](f: V => U): RDD[(K, U)]
将将RDD[K-V]转换成RDD[k,f[V=>U]] = RDD[k,U]操作,
即对value中值进行map映射,key保持不变
7.flatMapValues
def flatMapValues[U](f: V => TraversableOnce[U]): RDD[(K, U)]
针对RDD[(k,v)] 将其转换成RDD[(K, U)]
也是针对每一个value进行flatmap映射,转换成一个集合TraversableOnce[U]
8.countByKey
def countByKey(): Map[K, Long]
对每一个key计数,返回最终每一个key出现多少次
实现:self.mapValues(_ => 1L).reduceByKey(_ + _).collect().toMap
9.def partitionBy(partitioner: Partitioner): RDD[(K, V)]
重新对RDD进行partition分组,即shuffle环节
10.groupByKey
groupByKey(partitioner: Partitioner): RDD[(K, Iterable[V])]
按照key分组,然后每一个组内的所有元素组成迭代器集合,和combine区别是,没有对组内相同元素做运算,而是仅仅简单的将相同的元素进行集合收集。
11.cogroup与groupWith是同一个函数,只是groupWith是别名而已
def cogroup[W1, W2, W3](other1: RDD[(K, W1)],
      other2: RDD[(K, W2)],
      other3: RDD[(K, W3)],
      partitioner: Partitioner)
      : RDD[(K, (Iterable[V], Iterable[W1], Iterable[W2], Iterable[W3]))]
RDD本身与其他三个RDD进行各种join操作,按照相同的key进行分组。
返回值k就是相同的key,value就是四个RDD在相同key后的四个集合,这四个集合可以做各种笛卡尔乘积
12.def join[W](other: RDD[(K, W)], partitioner: Partitioner): RDD[(K, (V, W))]
仅仅操作两张表关联,调用cogroup方法,然后对相同key的两个集合进行笛卡尔乘积
正常情况下应该是一对多关系的两个表

同理 左关联
leftOuterJoin
def leftOuterJoin[W](
      other: RDD[(K, W)],
      partitioner: Partitioner): RDD[(K, (V, Option[W]))]
右关联
def rightOuterJoin[W](other: RDD[(K, W)], partitioner: Partitioner)
      : RDD[(K, (Option[V], W))]
全表关联
def fullOuterJoin[W](other: RDD[(K, W)], partitioner: Partitioner)
      : RDD[(K, (Option[V], Option[W]))]
都是调用cogroup方法,然后对相同key的两个集合进行相关联的笛卡尔乘积运算

13.def collectAsMap(): Map[K, V]
对RDD[K,V]进行action行为collect调用,收集好的数据转换成Map<K,V>

14.lookup(key: K)
def lookup(key: K): Seq[V]
找到该key对应的所有value值集合
这个会出发action行为,如果定义了如何根据key拆分不同的partition,则直接到指定partition中查找该key对应的value集合即可

15.SubtractedRDD
def subtractByKey[W: ClassTag](other: RDD[(K, W)]): RDD[(K, V)]
对两个rdd进行交互,获取RDD1存在,RDD2不存在数据,即差异的元素

16.saveAsHadoopFile
  def saveAsHadoopFile(
      path: String,
      keyClass: Class[_],
      valueClass: Class[_],
      outputFormatClass: Class[_ <: OutputFormat[_, _]],
      conf: JobConf = new JobConf(self.context.hadoopConfiguration),
      codec: Option[Class[_ <: CompressionCodec]] = None): Unit
将RDD的内容写入到hdfs上,因为这个RDD是K-V类型的RDD,因此只要指定outputFormatClass即可,这类型是满足key-value结构的。
同时指定path和压缩方式
实现逻辑:
执行RDD的action,RDD的每一个partition分区就会写入到hdfs对应的path路径下,因为path已知,partition也已知,因此根据这两个就可以知道一个文件的路径。
因此在hdfs上创建该文件的输出流,就可以向里面写入数据了

17.基础方法
  /**
   * 返回所有的key组成的RDD
   */
  def keys: RDD[K] = self.map(_._1)

  /**
   * 返回所有的value组成的RDD
   */
  def values: RDD[V] = self.map(_._2)

  //key对应的class
  private[spark] def keyClass: Class[_] = kt.runtimeClass

  //VALUE对应的class
  private[spark] def valueClass: Class[_] = vt.runtimeClass

  //key对应的排序对象算法
  private[spark] def keyOrdering: Option[Ordering[K]] = Option(ord)

18.未看懂并且也并不是很常用的函数,留着后续看
a.countApproxDistinctByKey
  def countApproxDistinctByKey(relativeSD: Double,numPartitions: Int): RDD[(K, Long)]
返回RDD中每一个key对应的value的不重复的次数的近似值
该方法调用的第三方实现的,具体实现算法就是HyperLogLogPlus算法
b.countByKeyApprox
def countByKeyApprox(timeout: Long, confidence: Double = 0.95) : PartialResult[Map[K, BoundedDouble]]
对K-V的信息仅抽取K,然后对K计算出现的次数,
即对每一个key计数,返回最终每一个key出现多少次,类似def countByKey(): Map[K, Long]
c.sampleByKey
 def sampleByKey(withReplacement: Boolean,
      fractions: Map[K, Double],
      seed: Long = Utils.random.nextLong): RDD[(K, V)]
抽样返回RDD的一个子集,用于抽样查看相关逻辑
