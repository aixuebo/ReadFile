一、背景与总结


二、map端小文件合并
1.executor读取hive表时单task处理数据量/无shuffle作业小文件合并
即同时满足，读取task数据源本身文件小 && 文件数量多 && 无shuffle场景下优化，即优化map端文件数量。
SET spark.hadoopRDD.targetBytesInPartition=134217728;//128M 是美团特有的参数

spark读取hive表时,默认每一个文件创建一个task,如果无shuffle,则每一个task执行完也会产生一个新的文件写回hdfs。这样就容易产生小文件问题。
该参数在一个task里读取多个文件,即如果读取一个文件后,小于该阈值,则继续读取下一个文件,直到超过该阈值后停止读取文件。因此减少小文件。
比如原来有1000个文件，都是小文件，本来要1000个task处理，产生1000个结果文件。经过配置后，需要10个task处理，因此产生了10个文件。

