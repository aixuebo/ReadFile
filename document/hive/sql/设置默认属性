一、设置reduce数量
set mapred.reduce.tasks = 5;

注意:
1.一定要在-------------之前设置,否则会抛异常
2.set mapred.reduce.tasks = 5;前面一定不能是-----,否则会说解析语法错误,就直接设置set mapred.reduce.tasks = 5;即可

hive <<EOF

set mapred.reduce.tasks = 5;

-------------
sql

quit;
EOF

二、自动map端join优化
set hive.auto.convert.join = true;
set hive.mapjoin.smalltable.filesize = 30000000.  30M
默认是开启join在map端自动优化功能的,但是有时候会因为内存不够,导致出现 java.lang.OutOfMemoryError: GC overhead limit exceeded
因此有时候需要将其关闭掉,即set hive.auto.convert.join = false;

一般出现的异常输出提示是:Starting to launch local task to process map join;      maximum memory =
导致重试很多次map端在本地执行任务,都失败,失败次数超过了一定伐值,因此任务fault,没有reduce输出产生。
  

三、设置引擎是tez
set hive.execution.engine=tez;


四、设置hive的执行名字
set mapred.job.name='topic_order-detail-1-${create_time}';
五、设置hive的输出文件后缀
set hive.output.file.extension=.c1;

六、设置动态分区
a.set hive.exec.dynamic.partition.mode=nostrick;
b.insert overwrite table dim.topic_user_partition partition(log_day)
c.select的最后几个字段的值就是分区的值

七、set hive.mapred.mode=nostrict; 取消hive的约束,即查询分区表的时候,如果不写分区字段,也是允许执行的

八、更换队列
mapreduce.job.queuename=queue1