一、原理
1.hive存储在hdfs上的内容永远都是字节数组,key是WritableComparable,value是Writable类型
2.而hive对用户表现的是只支持几种数据类型
因此用户设置的value都是数据类型方式,比如struct类型,此时是java对象,可以获取该struct中任意数据
3.用规定的序列化方式,将各种value的数据转换成Writable类型,因此就可以存储到hive中了

因此反序列化对象中保持了如何序列化和反序列化,以及待序列化的value的数据类型,比如struct类型。



reader过程
1.每次读取一行数据,即一个key是WritableComparable,value是Writable类型
2.对value进行反序列化
即将Writable类型数据转换成struct对象内容。
3.因为struct内容有所有一行的数据,因此需要那个字段就直接get即可
因此可以获取到需要的任意字段内容。
4.为了对外提供一致的模型,将所有需要的字段转换成HCatRecord对象。
而为了构建HCatRecord对象,需要用户提供一组输出的schema,那么会根据用户的schema顺序,将HCatRecord对象填充好。
这样用户在map-reduce中就可以直接使用value为HCatRecord对象进行处理了，里面的数据都是用户自定义的字段以及类型。

序列化类详细参见LazySimpleSerDe这个类

writer过程
